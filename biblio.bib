
@article{pereira_benchmarking_2018,
  title = {Benchmarking {{Pub}}/{{Sub IoT}} Middleware Platforms for Smart Services},
  issn = {2199-4668, 2199-4676},
  doi = {10.1007/s40860-018-0056-3},
  abstract = {Middleware is being extensively used in Internet of Things (IoT) deployments and is available in a variety of flavors. Despite this extensive use and diversity, a fair comparison of the benefits, disadvantages, and performance of each middleware platform is missing. This comparison is relevant to support the decision process for IoT infrastructure. In this paper, we propose a set of qualitative and quantitative dimensions for benchmarking IoT middleware. We use the publication\textendash{}subscription of a large dataset as use case inspired by a smart city scenario to compare two middleware platforms with standard ambition: FIWARE and oneM2M. We take these metrics and use case and systematically compare the two middleware platforms in the wild. We identify inefficiencies in implementations and characterize performance variations throughout the day, showing that the metrics may also be used for monitoring. Furthermore, we apply the same metrics and use case to two brokers set up in a controlled environment, providing infrastructure- and networking-independent insights. Finally, we summarize useful practical know-how acquired in the process that can speed up entrance into the topic and avoid configuration and implementation pitfalls that impact performance.},
  language = {en},
  journal = {Journal of Reliable Intelligent Environments},
  author = {Pereira, Carlos and Cardoso, Jo{\~a}o and Aguiar, Ana and Morla, Ricardo},
  month = feb,
  year = {2018},
  pages = {1--13},
  file = {/home/luis/Zotero/storage/9BAUCS8M/Pereira et al. - 2018 - Benchmarking PubSub IoT middleware platforms for .pdf;/home/luis/Zotero/storage/2D2IYUUT/s40860-018-0056-3.html}
}



@inproceedings{cardoso_benchmarking_2017,
  title = {Benchmarking {{IoT}} Middleware Platforms},
  doi = {10.1109/WoWMoM.2017.7974339},
  abstract = {Middleware is being extensively used in Internet of Things (IoT) deployments and is available in a variety of flavors - from general-purpose community-driven middleware and telco-developed Machine-to-Machine (M2M) middleware to middleware targeting specific deployments. Despite this extensive use and diversity, little is known about the benefits, disadvantages, and performance of each middleware platform and how the different platforms compare with each other. This comparison is especially relevant to help the design and dimensioning of IoT infrastructure. In this paper, we propose a set of qualitative dimensions and quantitative metrics that can be used for bench-marking IoT middleware. We use the publication-subscription of a large dataset as use case inspired by a smart city scenario to compare two middleware platforms. The methodology enables us to systematically compare the two middleware platforms. Further, we are able to use our approach to identify inefficiencies in implementations and to characterize performance variations throughout the day, showing that the metrics may also be used for monitoring.},
  booktitle = {2017 {{IEEE}} 18th {{International Symposium}} on {{A World}} of {{Wireless}}, {{Mobile}} and {{Multimedia Networks}} ({{WoWMoM}})},
  author = {Cardoso, J. and Pereira, C. and Aguiar, A. and Morla, R.},
  month = jun,
  year = {2017},
  keywords = {Internet of Things,middleware,Middleware,benchmark testing,Context modeling,IoT middleware platforms benchmarking,Machine-to-machine communications,Measurement,Publish-subscribe,qualitative dimensions,quantitative metrics,Sensors,software metrics,software performance evaluation,Standards},
  pages = {1--7},
  file = {/home/luis/Zotero/storage/QFIIBN4W/Cardoso et al. - 2017 - Benchmarking IoT middleware platforms.pdf;/home/luis/Zotero/storage/2MGUT5Q2/7974339.html}
}


